ğŸ©º Medical Chatbot (LLM + Retrieval-Augmented Generation)

A Medical Chatbot built using LangChain, Hugging Face LLMs, and FAISS vector database.
The chatbot answers medical-related questions strictly from provided documents, ensuring grounded and reliable responses using Retrieval-Augmented Generation (RAG).

ğŸš€ Features

ğŸ’¬ Ask medical questions in natural language

ğŸ§  Uses Mistral-7B-Instruct LLM via Hugging Face

ğŸ“š Retrieves answers from a FAISS vector database

âŒ Avoids hallucinations by answering only from context

ğŸ” Returns source documents along with answers

ğŸ§© Custom prompt to control LLM behavior

ğŸ› ï¸ Tech Stack

Python

LangChain

Hugging Face Inference API

Mistral-7B-Instruct

FAISS Vector Store

Sentence Transformers

Environment Variables for Security

ğŸ“ Project Structure
medical-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Main chatbot application
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/            # FAISS vector database
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ .env                     # Environment variables (not committed)

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/YOUR-USERNAME/YOUR-REPO.git
cd medical-chatbot

2ï¸âƒ£ Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate        # Linux / Mac
venv\Scripts\activate           # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Hugging Face Token

Create a .env file in the root directory:

HF_TOKEN=your_huggingface_api_token_here


Or set it directly in your terminal:

export HF_TOKEN=your_token_here     # Linux / Mac
set HF_TOKEN=your_token_here        # Windows

â–¶ï¸ Running the Chatbot
python app.py


You will be prompted with:

Write Query Here:


Enter your medical question and get:

âœ… Answer

ğŸ“„ Source documents used

ğŸ§  How It Works (High Level)

User enters a medical query

Query is converted into embeddings

FAISS retrieves relevant documents

Context + query is sent to Mistral LLM

LLM generates a grounded response

The chatbot does not answer outside the provided context, ensuring safer outputs. 

53085c05-9e01-4552-aa20-07e5405â€¦

âš ï¸ Disclaimer

This chatbot is not a replacement for professional medical advice.
Always consult a qualified healthcare professional for medical concerns.

ğŸ“Œ Future Improvements

Add Streamlit / Web UI

Support PDF uploads

Multi-document ingestion

Chat history memory

Better prompt tuning

ğŸ¤ Contributing

Pull requests are welcome!
For major changes, please open an issue first.

â­ Acknowledgements

Hugging Face

LangChain

Mistral AI

FAISS



